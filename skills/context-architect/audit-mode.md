# AUDIT Mode

Analyze existing context files for over-specification, structural issues, redundancy, and broken links.
Produces a scored report with concrete auto-fix proposals — nothing changes until the user approves.

## Scope Discovery

Build the audit scope before any analysis begins.

### Step 1: Parse Index Links

Read `CLAUDE.md` and extract every file link (markdown links, relative paths). Each linked file enters the audit scope.

### Step 2: Check Manifest

If `.context-architect.json` exists in the project root, merge its configuration:

```json
{
  "context_files": ["CLAUDE.md", ".claude/**"],
  "reference_docs": ["src/auth/ARCHITECTURE.md"],
  "ignore": ["docs/plans/**"],
  "probe_model": "sonnet"
}
```

- `context_files` — additional Layer 1 files to include
- `reference_docs` — additional Layer 2 files to include
- `ignore` — globs to exclude from scope
- `probe_model` — model for Knowledge Diff sub-agent (default: `sonnet`)

If no manifest exists, link-based scope from Step 1 is sufficient.

### Step 3: Confirm Scope

Present the discovered file list to the user:

```
Audit scope:
  Layer 1: CLAUDE.md
  Layer 2: docs/CONVENTIONS.md, src/auth/ARCHITECTURE.md, ...
  Ignored: docs/plans/**

Proceed? [Y/n]
```

Wait for confirmation before running phases.

---

## Phase 1: Structural Analysis

Detect anti-patterns in context file structure.

```bash
node ${CLAUDE_PLUGIN_ROOT}/tools/detect-antipatterns.mjs --phase structure --root .
```

### Checks

| Anti-Pattern | Detection Rule |
|---|---|
| **Monolith** | Single file 300+ lines |
| **Role soup** | Behavior + tools + style + build topics mixed in one file |
| **Tool forcing** | Directives like "always use X", "never use Y" for tool selection |
| **Directory dump** | Full directory tree listing embedded in context |
| **Lint dump** | Lint/formatter rules copied verbatim into context |
| **README echo** | Content duplicated from README.md |
| **Philosophy essay** | Abstract design philosophy paragraphs with no actionable rules |
| **Index-content leak** | CLAUDE.md contains actual content instead of links to docs |

Each finding includes: file path, line range, anti-pattern type, and severity.

---

## Phase 2: Docs Analysis

Analyze reference docs (Layer 2) for structural quality.

```bash
node ${CLAUDE_PLUGIN_ROOT}/tools/detect-antipatterns.mjs --phase docs --root .
```

### Checks

| Anti-Pattern | Detection Rule |
|---|---|
| **Header-less doc** | No `#` heading at the start of the file — purpose unclear |
| **Fat doc** | Single doc exceeds 200 lines |
| **Single-role violation** | Doc covers multiple unrelated topics (should be split) |

---

## Phase 3: Link Integrity

Verify all links between Layer 1 and Layer 2 are valid.

```bash
node ${CLAUDE_PLUGIN_ROOT}/tools/detect-antipatterns.mjs --phase links --root .
```

### Checks

| Issue | Detection Rule |
|---|---|
| **Broken link** | Index references a file that does not exist |
| **Orphan doc** | Reference doc exists but is not linked from any index file |

---

## Phase 4: Knowledge Diff

The most important phase. Tests whether context tells the AI things it already knows.

### Step 1: Extract Batched Prompts

```bash
node ${CLAUDE_PLUGIN_ROOT}/tools/knowledge-probe.mjs --root . --extract --batch
```

Output: JSON array of batch objects, each containing a `prompt` field ready for a sub-agent.

```json
[
  {
    "batch_id": 1,
    "statements": ["All components use PascalCase", "Tests use vitest", "..."],
    "prompt": "You are a knowledge probe agent..."
  }
]
```

### Step 2: Probe Sub-Agents

For each batch, spawn a sub-agent using the Task tool:

- **subagent_type:** `general-purpose`
- **model:** from `.context-architect.json` → `probe_model` (default: `sonnet`)
- **prompt:** `batch.prompt` (use the prompt exactly as generated by the CLI)
- **Isolation:** The sub-agent must NOT read any project files. The prompt enforces this.

The sub-agent responds with a JSON array of classifications:

```json
[
  {
    "statement": "All components use PascalCase",
    "question": "In React, what is the standard component naming convention?",
    "answer": "PascalCase",
    "classification": "REDUNDANT",
    "reason": "Standard React convention"
  }
]
```

### Step 3: Aggregate Results

Merge all batch results into a single list. Group by classification:

| Classification | Meaning | Action |
|---|---|---|
| **REDUNDANT** | AI already knows this | Recommend removal |
| **UNIQUE** | Project-specific knowledge | Keep |
| **REVIEW** | Partial match | Present to user for decision (in user's language) |

### Step 4: CCS Integration

Add a `duplicate_info` factor to the CCS report based on REDUNDANT count:

| REDUNDANT count | CCS Score |
|-----------------|-----------|
| 1-3             | +1        |
| 4-7             | +2        |
| 8+              | +3        |

This factor is added at the skill level — the CCS CLI output is augmented in the report, not modified in ccs-score.mjs.

### Step 5: User Report + Removal Diffs

Present Phase 4 results in the report:

```
Phase 4 — Knowledge Diff:
  [REDUNDANT] "All components use PascalCase" → AI standard (remove)
  [REDUNDANT] "Tests use vitest" → inferable from config (remove)
  [REVIEW] "API errors use AppError class" → partial match (user decides)
  [UNIQUE] "Deploy with ./scripts/deploy.sh staging" → keep
```

For each REDUNDANT item, generate a removal diff:

```diff
- All components use PascalCase
```

Present diffs to the user. Apply only after explicit approval per item.

---

## CCS Calculation

After all phases complete, calculate the Context Complexity Score.

```bash
node ${CLAUDE_PLUGIN_ROOT}/tools/ccs-score.mjs --root .
```

### CCS Factors

| Factor | Score |
|--------|-------|
| Single file 300+ lines | +3 |
| Role mixing | +2 |
| Tool forcing | +2 |
| Duplicate information | +1 |
| No docs separation | +1 |
| Orphan doc | +1 |
| Broken link | +2 |
| Header-less doc | +1 |
| Fat doc (200+ lines) | +2 |
| Index-content leak | +2 |

### Rating Scale

| CCS Score | Rating | Meaning |
|-----------|--------|---------|
| 0-2 | **Safe** | Context is well-structured and minimal |
| 3-5 | **Risk** | Over-specification detected, improvements recommended |
| 6+ | **High Over-Specification** | Significant restructuring needed |

---

## Report Generation

Present all results using the standard 6-item output format. All user-facing text MUST be in the **user's language**.

### 1. Current State Summary

Describe what exists: file count, total line count, layer structure, scope.

### 2. Risk Rating

Map CCS score to rating:
- **Low** — CCS 0-2 (Safe)
- **Medium** — CCS 3-5 (Risk)
- **High** — CCS 6+ (High Over-Specification)

### 3. Over-specification Detection

List all findings from Phase 1-4, grouped by phase:

```
Phase 1 — Structure:
  [WARNING] CLAUDE.md: monolith (342 lines)
  [WARNING] CLAUDE.md: role soup (behavior + build + style mixed)

Phase 2 — Docs:
  [WARNING] docs/CONVENTIONS.md: fat doc (267 lines)

Phase 3 — Links:
  [ERROR] CLAUDE.md:15 → docs/DEPLOY.md (broken link)
  [WARNING] docs/OLD_NOTES.md (orphan — not linked from index)

Phase 4 — Knowledge Diff:
  [REDUNDANT] "React uses JSX for templates" (AI knows this)
  [REDUNDANT] "Use async/await for async operations" (AI knows this)
  [REVIEW] "AppError class hierarchy" (partial match — user decides)
  [UNIQUE] "Deploy requires VPN access" (keep)
```

### 4. Structure Proposals

Map Phase 1-3 findings to concrete restructuring actions. Read actual file headings to determine split points.

**Finding-to-proposal mapping:**

| Finding | Proposal |
|---------|----------|
| monolith (300+ lines) | Split into N docs by top-level headings. Index keeps links only. |
| index_content_leak | Move code blocks and long paragraphs to `docs/`, replace with links. |
| role_mixing | Separate into role-specific docs (e.g., `conventions.md`, `testing.md`, `deploy.md`). |
| fat_doc (200+ lines) | Split by `##` headings into smaller focused docs. |
| orphan_doc | Add link to index, or recommend deletion if outdated. |
| broken_link | Suggest correct target path, or remove if target no longer exists. |

**Output format:**

```
Structure Proposals:
  1. CLAUDE.md (342 lines) → split into 3
     - CLAUDE.md (index, ~30 lines) — links only
     - docs/conventions.md — style/naming sections (lines 45-120)
     - docs/testing.md — test sections (lines 121-200)
     Savings: ~250 tokens removed from index injection

  2. docs/ARCHITECTURE.md (267 lines) → split into 2
     - docs/architecture.md — design overview
     - docs/api-reference.md — API details

  3. docs/old-notes.md — orphan, not linked from CLAUDE.md
     → Add link to index or delete?
```

Each proposal MUST include the source line ranges where content will be moved from.
When a monolith or fat_doc is proposed for splitting, read the file's headings to determine natural split points.

### 5. Fix Proposals — Deletion Diffs

For Phase 4 REDUNDANT items, present line-level removal diffs with approval controls.

**REDUNDANT items:**

```
Deletion Proposals (REDUNDANT, {count} items):

1. {file}:{line}
   - {statement text}
   Reason: {reason from sub-agent}

2. {file}:{line}
   - {statement text}
   Reason: {reason from sub-agent}

Apply: 1,2,3 / all / none
```

**REVIEW items:**

```
Needs Review (REVIEW, {count} items):

{N}. {file}:{line}
   "{statement text}"
   AI assessment: {reason from sub-agent}
   → keep / remove?
```

**User controls:**
- Individual: `1,3` — apply only selected items
- Bulk: `all` — apply all REDUNDANT deletions at once
- Skip: `none` — apply nothing
- Each REVIEW item is decided individually (keep / remove)

**Applying deletions:**
- For each approved deletion, remove the exact line from the file using Edit tool
- After all deletions, re-run `token-estimate.mjs` to show actual savings
- Present before/after token comparison

### 6. Token Impact

Run the token estimator:

```bash
node ${CLAUDE_PLUGIN_ROOT}/tools/token-estimate.mjs --root .
```

Use the output to calculate before/after numbers. Present in this format:

```
Token Impact:
  Current index injection: ~{index_tokens} tokens ({context_file})
  Current total context: ~{total_tokens} tokens (index + {linked_count} linked docs)

  Removable (REDUNDANT): ~{redundant_tokens} tokens ({redundant_count} statements)
  Separable (index → linked): ~{separable_tokens} tokens (content leak items)

  Estimated savings: ~{savings} tokens/conversation ({percentage}% reduction)
```

**Calculation rules:**
- `index_tokens` = tokens from files with `role: "index"` in token-estimate output
- `total_tokens` = `estimated_tokens` from token-estimate output
- `redundant_tokens` = sum of `Math.ceil(statement.length / 4)` for each REDUNDANT statement from Phase 4
- `separable_tokens` = estimate of content identified as `index_content_leak` in Phase 1
- `savings` = `redundant_tokens + separable_tokens`
- `percentage` = `Math.round(savings / index_tokens * 100)`

Numbers MUST be concrete (e.g., "~200 tokens"), not vague (e.g., "some savings").

---

## Process Summary

```
1. Discover scope (parse index + manifest)
2. Confirm scope with user
3. Phase 1: Structural analysis     → detect-antipatterns.mjs --phase structure
4. Phase 2: Docs analysis           → detect-antipatterns.mjs --phase docs
5. Phase 3: Link integrity          → detect-antipatterns.mjs --phase links
6. Phase 4: Knowledge diff          → knowledge-probe.mjs --extract --batch + sub-agents
7. Calculate CCS                    → ccs-score.mjs
8. Estimate tokens                  → token-estimate.mjs
9. Generate report (6-item format)
10. Present auto-fix proposals
11. Apply fixes only after user approval
```

## Reminders

- **User language rule:** All user-facing output MUST be in the user's language.
- **No changes without approval:** Present proposals, wait for explicit approval per fix, then apply.
- **Iron Law applies:** Every piece of context must justify its presence. Audit verifies this.
- **Sub-agent isolation:** The Knowledge Diff sub-agent must have ZERO project context to produce valid probes.
- **`${CLAUDE_PLUGIN_ROOT}` resolution:** When running tool commands, resolve `${CLAUDE_PLUGIN_ROOT}` to the plugin's actual installation directory.
